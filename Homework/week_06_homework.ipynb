{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6 - Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Put your code in functions and use default arguments as makes sense. You are now expected to use at least some functions in your code to make it reusable. We will check that there is at least one function in your code when grading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit: Use type hints in your functions to make sure you are using the right types when you call the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Clean your dataset to turn categorical values into numerical ones. One-hot encoding is likely the answer, but it depends on the dataset. Your data may have ordinal columns, for example where one-hot encoding is not as appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cc_main_df = pd.read_csv(\"../Misc./Credit_card.csv\")\n",
    "cc_label_df = pd.read_csv(\"../Misc./Credit_card_label.csv\")\n",
    "cc_combined_df = pd.merge(cc_main_df, cc_label_df, on = \"Ind_ID\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/xzwg3k5d0nqb3574ynkvzc740000gn/T/ipykernel_92069/490959497.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cc_combined_df.fillna(method = 'ffill', inplace=True)\n",
      "/var/folders/jq/xzwg3k5d0nqb3574ynkvzc740000gn/T/ipykernel_92069/490959497.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  cc_combined_df.replace(ordinal_mappers, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "cc_combined_df.fillna(method = 'ffill', inplace=True)\n",
    "ordinal_mappers = {\"EDUCATION\": {\"Lower secondary\": 1, \"Secondary / secondary special\": 2, \"Incomplete higher\": 3, \"Higher education\": 4, \"Academic degree\": 5}}\n",
    "cc_combined_df.replace(ordinal_mappers, inplace = True)\n",
    "\n",
    "one_hot_columns = [\"GENDER\", \"Car_Owner\", \"Propert_Owner\", \"Type_Income\", \"Marital_status\", \"Housing_type\", \"Type_Occupation\"]\n",
    "cc_combined_df = pd.get_dummies(cc_combined_df, columns = one_hot_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Perform univariate linear regression on the dataset. Select your variable to predict. How well did this model perform? Is this a good approach for this dataset? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Score: -2.7780671829797753e+25\n",
      "Mean Squared Error: 2.7592448061821554e+24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def linear_regression_train(X_train: np.ndarray, y_train: np.ndarray) -> LinearRegression:\n",
    "    sc = StandardScaler()\n",
    "    X_train_scaled = sc.fit_transform(X_train)\n",
    "    regression = LinearRegression().fit(X_train_scaled, y_train)\n",
    "    return regression\n",
    "\n",
    "def regression_performance(regression: LinearRegression, X_test_scaled: np.ndarray, y_test: np.ndarray) -> tuple:\n",
    "    y_predicted = regression.predict(X_test_scaled)\n",
    "    r2 = r2_score(y_test, y_predicted)\n",
    "    mse = mean_squared_error(y_test, y_predicted)\n",
    "    return r2, mse\n",
    "\n",
    "X = cc_combined_df.drop(columns = ['Ind_ID', 'EMAIL_ID', 'label'])\n",
    "y = cc_combined_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 9383028)\n",
    "\n",
    "regression_model = linear_regression_train(X_train, y_train)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_test_scaled = sc.fit_transform(X_test)\n",
    "\n",
    "r2_score_value, mse_score = regression_performance(regression_model, X_test_scaled, y_test)\n",
    "print(\"R-squared Score:\", r2_score_value)\n",
    "print(\"Mean Squared Error:\", mse_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Non-normalized R-squared Score and Mean Squared Error of 0.102 and 0.951, respectively... SEE PROBLEM 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is NOT a good approach for this dataset, since we're trying to predict BINARY outputs, and the linear regression predicts values well outside the 0 --> 1 (True, or False) range. In other words, the extentuating values are NOT interpretable... what could \"45\" mean in the context of this dataset? Instead, we should use logistic regression, whose values are interpretable as probabilites/leverage between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Perform KNN on this dataset. As part of this, write a function that selects the optimal value of k. How well did this model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K is: 12\n",
      "Accuracy: 0.8817204301075269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def train_knn(X_train: np.ndarray, y_train: np.ndarray, k: int) -> KNeighborsClassifier:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "def select_optimal_k(X_train: np.ndarray, y_train: np.ndarray, max_k: int = 13, cv: int = 5) -> int:\n",
    "    optimal_k = 1\n",
    "    max_score = 0\n",
    "    for k in range(1, max_k + 1):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv = cv)\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > max_score:\n",
    "            max_score = avg_score\n",
    "            optimal_k = k\n",
    "    return optimal_k\n",
    "\n",
    "optimal_k = select_optimal_k(X_train, y_train)\n",
    "\n",
    "knn = train_knn(X_train, y_train, optimal_k)\n",
    "\n",
    "performance = knn.score(X_test, y_test)\n",
    "print(\"Optimal K is:\", optimal_k)\n",
    "print(\"Accuracy:\", performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Non-normalized accuracy of 0.879... SEE PROBLEM 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN is incredibly accurate, due in large part to the advantage it has reducing noise and sticking to only the nearest \"neighborhood\" in a (relatively) large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Work with your dataset to perform logistic regression. How well did this perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886021505376344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def logistic_regression_train(X_train: np.ndarray, y_train: np.ndarray) -> LogisticRegression:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    logistic_reg = LogisticRegression()\n",
    "    logistic_reg.fit(X_train_scaled, y_train)\n",
    "    return logistic_reg\n",
    "\n",
    "def logistic_regression_performance(logistic_reg: LogisticRegression, X_test_scaled: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    y_pred = logistic_reg.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "X = cc_combined_df.drop(columns = ['Ind_ID', 'EMAIL_ID', 'label'])\n",
    "y = cc_combined_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 18030)\n",
    "\n",
    "logistic_reg_model = logistic_regression_train(X_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "accuracy = logistic_regression_performance(logistic_reg_model, X_test_scaled, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (Non-normalized accuracy of 0.879... SEE PROBLEM 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we hypothesized earlier, a logistic performed SIGNIFICANTLY better than a linear regression——given it squeesing the values between 0 and 1, our range——and only a little worse than our arguably more complex KNN function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.) Perform normalization on your dataset. Does it change the performance for 2-4? What is the best measure of performance for your dataset (accuracy or something else) and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After returning to the LinearRegression dataset and changing the function to use normalized data (see above), the R-squared of 0.102 and Mean-Squared Error of 0.095 dropped drastically to -2.778(e+25) and -2.592(e+24), respectively, meaning the performance fell from bad to horrific. This is likely due, in large part, to our Linear Regression overfitting the training data and essentially learning to predict its \"noise\"——that noise accentuated by normalizing——rather than predictions in general.\n",
    "\n",
    "In the case of logistic and KNN, normalizing nudged our accuracy in the right direction (made it more accurate), likely due to the fact doing so scaled features down to the same range, preventing those features with wider ranges from overwhelming those without."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of this problem, accuracy would almost certainly be the best measure of performance in the dataset, since we're trying to determine how many people actually recieved credit cards based on our models (TP, FP, binary outcomes), not the distance of our predictions from a mean, as in linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
