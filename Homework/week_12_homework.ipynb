{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 12 - Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Load the tokenized Paradise Lost from the Gutenberg Corpus in NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stem or lemmatize the words and find counts.\n",
    "- Exclude stop words and make sure you are including words of all capitalizations in your count. If there are any meaningless “words” (“thus” and single letters, etc.) that are produced in your list of top words, alter your logic to exclude them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/connorlove/Library/Python/3.9/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/connorlove/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/connorlove/Library/Python/3.9/lib/python/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/connorlove/Library/Python/3.9/lib/python/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/connorlove/Library/Python/3.9/lib/python/site-packages (from nltk) (4.66.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/connorlove/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/connorlove/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/connorlove/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/connorlove/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words:\n",
      "heaven\n",
      "god\n",
      "shall\n",
      "earth\n",
      "u\n",
      "man\n",
      "first\n",
      "day\n",
      "high\n",
      "one\n",
      "son\n",
      "far\n",
      "death\n",
      "power\n",
      "great\n",
      "till\n",
      "like\n",
      "world\n",
      "hell\n",
      "thing\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "pl = nltk.corpus.gutenberg.words('milton-paradise.txt')\n",
    "sw = set(stopwords.words('english'))\n",
    "other_stopwords = {'thou', 'thy', 'thee', 'thus', 'yet', 'though', 'may'}\n",
    "sw.update(other_stopwords)\n",
    "\n",
    "filtered_pl = [word.lower() for word in pl if word.isalnum() and word.lower() not in sw]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "paradise_lost_lemmatized = [lemmatizer.lemmatize(word) for word in filtered_pl]\n",
    "\n",
    "pl_word_freq = FreqDist(paradise_lost_lemmatized)\n",
    "\n",
    "print(\"Top 20 words:\")\n",
    "for word, freq in pl_word_freq.most_common(20):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select the top 20 words and create a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify why you chose stemming or lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose lemmatization since it's a more complex process—and is thusly, more accurate—than stemming. Although stemming will suffice for more simple requests, lemmatization, critically, considers the CONTEXT of a word where stemming does not, before returning its lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Perform Vader Sentiment Analysis on the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the 5 most negative, 5 most positive, and 5 most neutral sentences in Paradise Lost. This may take a while to run, so you can always start with a small subset of the data (100 sentences) and then once your code works as expected, expand it to the whole book and let it run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain your findings from the previous question. Are the sentences and their sentiment analysis scores correct? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra credit: create a word cloud for your results from question 1 (see chapter 21 in your book for how to do this)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
