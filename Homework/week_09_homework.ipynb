{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 9: Oversampling, undersampling, and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you are using functions. You will lose 2 pts if there are no functions in your code. Chapter 16 should have some important information related to SVM, otherwise, the material from class and referenced below should suffice for this. Use words to explain the results. Do not just show a confusion matrix or classification report.\n",
    "- Use type hints and make sure all your code except the import statements uses functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Perform additional cleaning beyond what you did in Assignment 6. Specify the improvements you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Original cleaning methods, converted into broadly applicable functions complete with type hints:\n",
    "\n",
    "def read_csv(files: List[str], on: str) -> pd.DataFrame:\n",
    "    \"\"\"Reads CSV files and merges them on a specified merge column\"\"\"\n",
    "    dfs = [pd.read_csv(file) for file in files]\n",
    "    combined_df = pd.merge(*dfs, on = on, how = \"inner\")\n",
    "    return combined_df\n",
    "\n",
    "def ffill_null_num(df: pd.DataFrame, method: str = 'ffill') -> pd.DataFrame:\n",
    "    \"\"\"Forward fills null numerical values in DataFrame\"\"\"\n",
    "    df.fillna(method = method, inplace = True)\n",
    "    return df\n",
    "\n",
    "def map_ordinal_values(df: pd.DataFrame, mappings: Dict[str, Dict[str, int]]) -> pd.DataFrame:\n",
    "    \"\"\"Maps ordinal values in DataFrame onto specified values\"\"\"\n",
    "    for column, mapper in mappings.items():\n",
    "        df[column] = df[column].map(mapper)\n",
    "    return df\n",
    "\n",
    "def one_hot_encode(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Performs one-hot encoding on specified columns of DataFrame.\"\"\"\n",
    "    df = pd.get_dummies(df, columns = columns)\n",
    "    return df\n",
    "\n",
    "# New, broadly applicable cleaning methods, also in functions, with respective type hints:\n",
    "\n",
    "# 1.) Standardize the data so it has equal weight in the model's computation:\n",
    "\n",
    "def scale_num(df: pd.DataFrame, columns_to_scale: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Scales specified numerical columns using MinMaxScaler\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    return df\n",
    "\n",
    "# 2.) Fills null CATEGORICAL values in dataframe with mode (most frequent) value of that column:\n",
    "\n",
    "def fill_null_cats(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Fills missing values in categorical columns with mode (most frequent value) of that column\"\"\"\n",
    "    return df.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Newly cleaned data:\n",
    "\n",
    "def clean_cc_data(main_data: str,\n",
    "                  label_data: str,\n",
    "                  ordinal_maps: Dict[str, Dict[str, int]],\n",
    "                  cat_missing_fill_cols: List[str],\n",
    "                  one_hot_cols: List[str],\n",
    "                  numerical_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Cleans credit card data\"\"\"\n",
    "    cc_data = [main_data, label_data]\n",
    "    cc_combined_df = read_csv(cc_data, on = \"Ind_ID\")\n",
    "    cc_combined_df = map_ordinal_values(cc_combined_df, ordinal_maps)\n",
    "    cc_combined_df = fill_null_cats(cc_combined_df, cat_missing_fill_cols)\n",
    "    cc_combined_df = ffill_null_num(cc_combined_df)\n",
    "    cc_combined_df = scale_num(cc_combined_df, numerical_cols)\n",
    "    cc_combined_df = one_hot_encode(cc_combined_df, one_hot_cols)\n",
    "    return cc_combined_df\n",
    "\n",
    "main_data = \"../Misc./Credit_card.csv\"\n",
    "label_data = \"../Misc./Credit_card_label.csv\"\n",
    "ordinal_maps = {\"EDUCATION\": {\"Lower secondary\": 1, \"Secondary / secondary special\": 2, \"Incomplete higher\": 3,\n",
    "                                  \"Higher education\": 4, \"Academic degree\": 5}}\n",
    "cat_missing_fill_cols = [\"GENDER\", \"Car_Owner\", \"Propert_Owner\", \"Type_Income\", \"Marital_status\", \"Housing_type\", \"Type_Occupation\"]\n",
    "one_hot_cols = [\"GENDER\", \"Car_Owner\", \"Propert_Owner\", \"Type_Income\", \"Marital_status\", \"Housing_type\", \"Type_Occupation\"]\n",
    "numerical_cols = [\"Annual_income\", \"Birthday_count\", \"Employed_days\", \"Family_Members\"]\n",
    "cleaned_cc_data = clean_cc_data(main_data, label_data, ordinal_maps, cat_missing_fill_cols, one_hot_cols, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Perform combined, oversampling, or undersampling on the dataset you selected for Assignment 6.  Explain why you chose what you did. How did this impact the results of your KNN and Logistic Regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "\n",
    "# Original KNN classification model, optimal k, and accuracy plugged into function format:\n",
    "\n",
    "def train_knn(X_train: np.ndarray, y_train: np.ndarray, k: int) -> KNeighborsClassifier:\n",
    "    \"\"\"Trains a KNN classifier with the given training data and k value.\"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "def select_optimal_k(X_train: np.ndarray, y_train: np.ndarray, max_k: int = 13, cv: int = 5) -> int:\n",
    "    \"\"\"Selects the optimal value of k using cross-validation.\"\"\"\n",
    "    optimal_k = 1\n",
    "    max_score = 0\n",
    "    for k in range(1, max_k + 1):\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv = cv)\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > max_score:\n",
    "            max_score = avg_score\n",
    "            optimal_k = k\n",
    "    return optimal_k\n",
    "\n",
    "def train_and_evaluate_knn(X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> Tuple[int, float]:\n",
    "    \"\"\"Trains a KNN classifier, selects the optimal k, and evaluates its performance.\"\"\"\n",
    "    optimal_k = select_optimal_k(X_train, y_train)\n",
    "    knn = train_knn(X_train, y_train, optimal_k)\n",
    "    accuracy = knn.score(X_test, y_test)\n",
    "    return optimal_k, accuracy\n",
    "\n",
    "\n",
    "X = cleaned_cc_data.drop(columns = ['Ind_ID', 'EMAIL_ID', 'label'])\n",
    "y = cleaned_cc_data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 9383028)\n",
    "\n",
    "optimal_k, accuracy = train_and_evaluate_knn(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"Optimal K is:\", optimal_k)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cc_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I chose Oversampling, because of the imbalance in the data skewed towards credit card approvals.\n",
    "# As can be seen in the value_counts above, there is a ratio of nearly 10 approvals to 1 denial,\n",
    "# so I aimed to improve the model by feeding it more instances of this minority:\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def oversample_random(X: np.ndarray, y: np.ndarray, test_size: float = 0.3, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Oversample with RandomOverSampler and split data back into train/test sets\"\"\"\n",
    "    ros = RandomOverSampler(random_state = random_state)\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = test_size, random_state = random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X = cleaned_cc_data.drop(columns = ['Ind_ID', 'EMAIL_ID', 'label']).values\n",
    "y = cleaned_cc_data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 9383028)\n",
    "\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = oversample_random(X_train, y_train)\n",
    "\n",
    "optimal_k, accuracy = train_and_evaluate_knn(X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled)\n",
    "\n",
    "print(\"Optimal K is:\", optimal_k)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling SIGNIFICANTLY improved the accuracy of the KNN model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Original Logistic Regression model, also plugged into function format:\n",
    "\n",
    "def lr_train(X_train: np.ndarray, y_train: np.ndarray) -> LogisticRegression:\n",
    "    \"\"\"Trains a logistic regression model.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    logistic_reg = LogisticRegression()\n",
    "    logistic_reg.fit(X_train_scaled, y_train)\n",
    "    return logistic_reg\n",
    "\n",
    "def lr_performance(logistic_reg: LogisticRegression, X_test_scaled: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the accuracy of the logistic regression model.\"\"\"\n",
    "    y_pred = logistic_reg.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate_lr(X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"Trains a logistic regression model and evaluates its performance.\"\"\"\n",
    "    logistic_reg_model = lr_train(X_train, y_train)\n",
    "    scaler = StandardScaler()\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    accuracy = lr_performance(logistic_reg_model, X_test_scaled, y_test)\n",
    "    return accuracy\n",
    "\n",
    "X = cleaned_cc_data.drop(columns = ['Ind_ID', 'EMAIL_ID', 'label']).values\n",
    "y = cleaned_cc_data['label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 18030)\n",
    "\n",
    "accuracy = train_and_evaluate_lr(X_train, X_test, y_train, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampled Logistic Regression:\n",
    "\n",
    "oversampled_lr_model = lr_train(X_train_resampled, y_train_resampled)\n",
    "accuracy = lr_performance(oversampled_lr_model, X_test_resampled, y_test_resampled)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling SIGNIFICANTLY worsened the accuracy of the logistic regression model... which could be due to overfitting, or the fundamental difference between KNN CLASSIFYING, as opposed to Logistic Regression PREDICTING results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create an ROC Curve for the model and calculate the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# KNN AUC and ROC Curve:\n",
    "\n",
    "def knn_auc(knn_model: KNeighborsClassifier, X_test_scaled: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"Calculates AUC and plots ROC curve for given KNN model\"\"\"\n",
    "    y_pred_proba = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    return auc\n",
    "\n",
    "def evaluate_knn_auc(X_test_scaled: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"Evaluates AUC of given KNN model\"\"\"\n",
    "    auc = knn_auc(knn_model, X_test_scaled, y_test)\n",
    "    print(\"AUC Score:\", auc)\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "evaluate_knn_auc(X_test_resampled, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression AUC and ROC curve:\n",
    "\n",
    "def lr_auc(logistic_reg: LogisticRegression, X_test_scaled: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"Calculates the AUC and plots the ROC curve of the logistic regression model.\"\"\"\n",
    "    y_pred_proba = logistic_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, marker ='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    return auc\n",
    "\n",
    "def evaluate_lr_auc(X_test_scaled: np.ndarray, y_test: np.ndarray) -> float:\n",
    "    \"\"\"Evaluates the AUC of the logistic regression model.\"\"\"\n",
    "    auc = lr_auc(oversampled_lr_model, X_test_scaled, y_test)\n",
    "    print(\"AUC Score:\", auc)\n",
    "    plt.show()\n",
    "    return auc\n",
    "\n",
    "evaluate_lr_auc(X_test_resampled, y_test_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Perform a linear SVM to predict the result from your dataset. How did the SVM model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_linear_svm(X_train: np.ndarray, X_test: np.ndarray, y_train: np.ndarray, y_test: np.ndarray) -> str:\n",
    "    \"\"\"Trains SVM model and evaluates accuracy\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    classifier = SVC(kernel = 'linear')\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    y_pred = classifier.predict(X_test_scaled)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return report\n",
    "\n",
    "classification_report = train_and_evaluate_linear_svm(X_train, X_test, y_train, y_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model operated... alright, predicting with great precision the 0, or negative class, but an incredibly poor recall of 7% for the 1—or positive—class. Although the net accuracy is optimstic, in our circumstance, recall matters more than any other metric in determining the accuracy of a model, given the company nets a huge loss if it gives a credit card to an unsuitable person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is outlier detection? Why is it important? What methods can you use for outlier detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier detection is the strategy of recognizing and flagging extreme data points among a set. This strategy has great weight in situations such as counter-terrorism and fraud, and the events at large in which an outlier almost certainly signifies some guaranteed threat. A box plot is a common use case of outlier detection, in which said extremes are represented as points outside a sort of \"whiskered box\", with lines on either end, or \"maximum\" cutoffs of 1.5 * Q1 and Q3, respectively. Another, more accurate method of outlier detection is IsolationForests, consisting of segmenting the data by columns, at random, and partition outliers among their multiple features. A final method is OneClassSVM, which more accurately defines the \"normal points\" which could be used in box plot representations by parsing through the noise of a dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
