{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11 - Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess the customer data. How are you handling nulls? What process(es) are you using to encode and normalize the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "customer_df = pd.read_csv('../Misc./customer_data.csv', encoding = 'unicode_escape')\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo           0\n",
       "StockCode           0\n",
       "Description      1454\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "UnitPrice           0\n",
       "CustomerID     135080\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After parsing through all the nulls in the \"Description\"—more appropriately titled \"item sold\"—column, it appears that for every missing value, the unit price is and Cusomter ID are likewise blank. This holds true no matter the month in question:\n",
    "\n",
    "For example, let's compare a few such offenders, beginning with row 21779:\n",
    "\n",
    "<538128,21357,,46,12/9/2010 15:54,0,,United Kingdom>\n",
    "\n",
    "...row 131742:\n",
    "\n",
    "<547626,20973,,60,3/24/2011 11:30,0,,United Kingdom>\n",
    "\n",
    "...and row 319903:\n",
    "\n",
    "<564920,48116,,8,8/31/2011 12:43,0,,United Kingdom>\n",
    "\n",
    "As demonstrated by all the above cases, the third column \"Description\" is null, the sixth column \"Unit Price\" equal to 0, and the seventh column \"Customer ID\" null. Such a pattern maintains in every entry featuring nulls in its description: again, that's the item sold. Then, the prevailing question looms, what should be done with these nulls? Well, I'm hesitant to take the conventional route of replacing them with the mode or median of the dataset, for fear of skewing my models. Further, the only useful feature these data harbor for the incumbent K-means and hierarchical clustering approaches are their \"quantity\" column—the fourth, above—but, for lack of an item or price, the context of the quantity is all but meaningless. With that ample justification behind us, I'll take the perhaps contentious, but I believe appropriate step of deleting the rows of data with nulls in their description. To further assuage doubt, this represents 1454/541911 = 0.003% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo           0\n",
       "StockCode           0\n",
       "Description         0\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "UnitPrice           0\n",
       "CustomerID     133626\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_df_cleaned = customer_df.dropna(subset = ['Description'])\n",
    "customer_df_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!\n",
    "\n",
    "As for the \"CustomerID\" column, those nulls won't actually be consequential to my modelling, given K-means and hierarchical clustering will attempt to categorize purchasers based on their orders. Including CustomerID would be including a perfect predictor of outcome, which defeats the entire purpose of unsupervised learning.\n",
    "\n",
    "However, I can, and will, drop the spaces from the items in the \"Description\" column, then One-hot Encoding the column. Dropping the spaces is a preemptive measure to prevent similar items from being encoded differently, due to typographic differences when they were entered; as I've skimmed the dataset, there appears to be at least some variability to this end. Moreover, I'm chosing to One-hot Encode because no natural order exists among these items: they're all equally valid, for my models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jq/xzwg3k5d0nqb3574ynkvzc740000gn/T/ipykernel_40249/1238725550.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customer_df_cleaned['Description'] = customer_df_cleaned['Description'].apply(lambda x: x.replace(' ', ''))\n"
     ]
    }
   ],
   "source": [
    "customer_df_cleaned['Description'] = customer_df_cleaned['Description'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df_cleaned_encoded = pd.get_dummies(customer_df_cleaned, columns = ['Description', 'Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, normalization. To further my thesis from earlier, I'll only be considering a select few features for these models. Let's take a look at those available to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['InvoiceNo', 'StockCode', 'Quantity', 'InvoiceDate', 'UnitPrice',\n",
      "       'CustomerID', 'Description_*BoomboxIpodClassic',\n",
      "       'Description_*USBOfficeMirrorBall', 'Description_10COLOURSPACEBOYPEN',\n",
      "       'Description_12COLOUREDPARTYBALLOONS',\n",
      "       ...\n",
      "       'Country_RSA', 'Country_Saudi Arabia', 'Country_Singapore',\n",
      "       'Country_Spain', 'Country_Sweden', 'Country_Switzerland', 'Country_USA',\n",
      "       'Country_United Arab Emirates', 'Country_United Kingdom',\n",
      "       'Country_Unspecified'],\n",
      "      dtype='object', length=4237)\n"
     ]
    }
   ],
   "source": [
    "print(customer_df_cleaned_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring the nearly 4200 one-hot encoding columns we just created, it seems that a few features should certainly not be considered, for the same reason CustomerID wasn't, including InvoiceNo, StockCode, and InvoiceDate. From a practical perspective, these sorts of data would either provide our models the same degree of perfect prediction that CustomerID would've—such as InvoiceNo and StockCode—or simply be confounding, overfitting-prone information—such as InvoiceDate. Then, we are left with four features—Description, Quantity, UnitPrice, and Country—to plug into our unsupervised models. As one-hot encoding has already situated Description and Country for binary classification, the only two features left to normalize are Quantity and UnitPrice, a step which is rather important given these distance-based forms of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_be_normalized = customer_df_cleaned_encoded[['Quantity', 'UnitPrice']]\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features_to_be_normalized)\n",
    "customer_df_cleaned_encoded[['Quantity', 'UnitPrice']] = normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Perform k-means on this dataset for customer segments. Customer segments help determine what types of people buy your product, which allows you to target more people like your usual customers. Should you look at all the data, or which subset of data should you use? What is the ideal number of clusters? Which approach did you use to find the ideal number of clusters and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Perform hierarchical clustering for customer segments. What is the ideal number of clusters? Which approach did you use to find the ideal number of clusters and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Compare the results of 2 and 3. Which approach do you think is best? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
